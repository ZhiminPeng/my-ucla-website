<pre style='color:#000000;background:#ffffff;'><html><body style='color:#000000; background:#ffffff; '><pre>
<span style='color:#3f7f59; '>/*</span>
<span style='color:#3f7f59; '>&#xa0;* Solve a distributed lasso problem, i.e.,</span>
<span style='color:#3f7f59; '>&#xa0;*    </span>
<span style='color:#3f7f59; '>&#xa0;*       min ||x||_1</span>
<span style='color:#3f7f59; '>&#xa0;*       s.t. Ax = b</span>
<span style='color:#3f7f59; '>&#xa0;* </span>
<span style='color:#3f7f59; '>&#xa0;* The implementation uses MPI for distributed communication</span>
<span style='color:#3f7f59; '>&#xa0;* and the GNU Scientific Library (GSL) for BLAS operations. </span>
<span style='color:#3f7f59; '>&#xa0;*</span>
<span style='color:#3f7f59; '>&#xa0;* Reference: W. Deng, M.-J. Lai, Z. Peng, and W. Yin, Parallel Multi-Block ADMM with o(1/k) Convergence, UCLA CAM 13-64, 2013. </span>
<span style='color:#3f7f59; '>&#xa0;* Date:     Jan 20, 2014</span>
<span style='color:#3f7f59; '>&#xa0;*/</span>

<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>stdio.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>stdlib.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>math.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>time.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>"</span><span style='color:#3f3fbf; '>mmio.h</span><span style='color:#2a00ff; '>"</span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>mpi.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>gsl/gsl_vector.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>gsl/gsl_matrix.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>gsl/gsl_blas.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>gsl/gsl_linalg.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>gsl/gsl_rng.h</span><span style='color:#2a00ff; '>></span>
<span style='color:#7f0055; '>#</span><span style='color:#7f0055; '>include </span><span style='color:#2a00ff; '>&lt;</span><span style='color:#3f3fbf; '>gsl/gsl_randist.h</span><span style='color:#2a00ff; '>></span>

<span style='color:#7f0055; font-weight:bold; '>void</span> soft_threshold(gsl_vector *v, <span style='color:#7f0055; font-weight:bold; '>double</span> k); <span style='color:#3f7f59; '>//soft thresholding function</span>

<span style='color:#3f7f59; '>// main function</span>
<span style='color:#7f0055; font-weight:bold; '>int</span> <span style='color:#7f0055; font-weight:bold; '>main</span>(<span style='color:#7f0055; font-weight:bold; '>int</span> argc, <span style='color:#7f0055; font-weight:bold; '>char</span> **argv) {

  <span style='color:#7f0055; font-weight:bold; '>int</span> rank;
  <span style='color:#7f0055; font-weight:bold; '>int</span> size;

  MPI_Init(&amp;argc, &amp;argv);               <span style='color:#3f7f59; '>// Initialize the MPI execution environment</span>
  MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); <span style='color:#3f7f59; '>// Determine current running process</span>
  MPI_Comm_size(MPI_COMM_WORLD, &amp;size); <span style='color:#3f7f59; '>// Total number of processes</span>


  <span style='color:#3f7f59; '>/* stopping criterions */</span>
  <span style='color:#7f0055; font-weight:bold; '>const</span> <span style='color:#7f0055; font-weight:bold; '>int</span> MAX_ITER  = 1000;   <span style='color:#3f7f59; '>// maximum number of iterations</span>
  <span style='color:#7f0055; font-weight:bold; '>const</span> <span style='color:#7f0055; font-weight:bold; '>double</span> tol    = 1e-6;   <span style='color:#3f7f59; '>// relative error tolerance</span>
  <span style='color:#7f0055; font-weight:bold; '>FILE</span> *test;                   <span style='color:#3f7f59; '>// write results to file</span>
  <span style='color:#7f0055; font-weight:bold; '>int</span> m;                        <span style='color:#3f7f59; '>// # of rows </span>
  <span style='color:#7f0055; font-weight:bold; '>int</span> n;                        <span style='color:#3f7f59; '>// # of columns</span>
  
  m = 1000;                   <span style='color:#3f7f59; '>// you can set it to a smaller size for fun</span>
  n = 2000/size;
  
  <span style='color:#7f0055; font-weight:bold; '>double</span> entry, startTime, endTime, commStartTime, commEndTime, totalStartTime, totalEndTime;
  <span style='color:#7f0055; font-weight:bold; '>char</span> s[100];

  <span style='color:#7f0055; font-weight:bold; '>int</span> row, col;    
  gsl_rng * rg;
  <span style='color:#7f0055; font-weight:bold; '>const</span> gsl_rng_type* T;
  gsl_rng_env_setup();
  T = gsl_rng_default;
  rg = gsl_rng_alloc(T);

  <span style='color:#3f7f59; '>/* Generate matrix A */</span>
  <span style='color:#7f0055; font-weight:bold; '>if</span>(rank==0)
  {
    <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>======================</span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
    <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>Start to generate A </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
    startTime = MPI_Wtime();
  }
  
  gsl_matrix *A = gsl_matrix_calloc(m, n);
  <span style='color:#3f7f59; '>// entries of matrix A from Gaussian distribution</span>
  <span style='color:#7f0055; font-weight:bold; '>for</span> (<span style='color:#7f0055; font-weight:bold; '>int</span> i = 0; i &lt; m*n; i++) 
  {
    row = i % m;
    col = <span style='color:#7f0055; font-weight:bold; '>floor</span>(i/m);
    entry = gsl_ran_gaussian(rg, 1.0);
    gsl_matrix_set(A, row, col, entry);
  }
  
  <span style='color:#7f0055; font-weight:bold; '>if</span>(rank==0)
  {
    <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>A is generated!</span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
    endTime = MPI_Wtime();
    <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>it takes </span><span style='color:#2a00ff; '>%lf</span><span style='color:#2a00ff; '> s to generate A! </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>, endTime - startTime);
  }

  <span style='color:#3f7f59; '>/* generate a sparse vector xs */</span>
  gsl_vector *xs = gsl_vector_calloc(n);
  <span style='color:#7f0055; font-weight:bold; '>int</span> k = 0.05*n;    <span style='color:#3f7f59; '>// k is the # of non-zeros</span>
  <span style='color:#7f0055; font-weight:bold; '>int</span> id;            <span style='color:#3f7f59; '>// id saves the location of the non-zero component;</span>
  
  <span style='color:#7f0055; font-weight:bold; '>if</span>(rank==0)
  {
    <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>======================</span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
    <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>Start to generate xs </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
  }
  <span style='color:#3f7f59; '>// generate the sparse vector xs</span>
  <span style='color:#7f0055; font-weight:bold; '>for</span>(<span style='color:#7f0055; font-weight:bold; '>int</span> j=0; j&lt;k;j++)
  {
    entry = gsl_ran_gaussian(rg, 1.0);
    id = <span style='color:#7f0055; font-weight:bold; '>rand</span>()%n;
    <span style='color:#7f0055; font-weight:bold; '>if</span>(entry>0) 
      gsl_vector_set(xs,  id, entry);
    <span style='color:#7f0055; font-weight:bold; '>else</span>
      gsl_vector_set(xs,  id, entry);
  }
  
  <span style='color:#7f0055; font-weight:bold; '>if</span>(rank==0) <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>xs is generated! </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
  
  
  <span style='color:#3f7f59; '>//caculate b  </span>
  gsl_vector *tmpb = gsl_vector_calloc(m);
  gsl_vector *b = gsl_vector_calloc(m);
  gsl_blas_dgemv(CblasNoTrans, 1, A, xs, 0, tmpb); <span style='color:#3f7f59; '>// Axs = b</span>
  MPI_Allreduce(tmpb->data, b->data,  m, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
  gsl_vector_free(tmpb);
  <span style='color:#7f0055; font-weight:bold; '>if</span>(rank==0) <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>b is generated! </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
  MPI_Barrier(MPI_COMM_WORLD);

  <span style='color:#3f7f59; '>/*</span>
<span style='color:#3f7f59; '>&#xa0;&#xa0;&#xa0;* These are all variables related to ADMM itself. There are many</span>
<span style='color:#3f7f59; '>&#xa0;&#xa0;&#xa0;* more variables than in the Matlab implementation because we also</span>
<span style='color:#3f7f59; '>&#xa0;&#xa0;&#xa0;* require vectors and matrices to store various intermediate results.</span>
<span style='color:#3f7f59; '>&#xa0;&#xa0;&#xa0;* The naming scheme follows the Matlab version of this solver.</span>
<span style='color:#3f7f59; '>&#xa0;&#xa0;&#xa0;*/</span> 
  
  <span style='color:#7f0055; font-weight:bold; '>double</span> rho = 10.0/gsl_blas_dasum(b);
  <span style='color:#7f0055; font-weight:bold; '>double</span> tau = 0.1 * size * rho;
  <span style='color:#7f0055; font-weight:bold; '>double</span> gamma = 1.0;
  
  <span style='color:#7f0055; font-weight:bold; '>double</span> dlam_nrm, lower_bnd, dx_nrm, cross_term;
  gsl_vector *x_old      = gsl_vector_calloc(n);  <span style='color:#3f7f59; '>// previous x</span>
  gsl_vector *x          = gsl_vector_calloc(n);  <span style='color:#3f7f59; '>// current x</span>
  gsl_vector *x_new      = gsl_vector_calloc(n);  <span style='color:#3f7f59; '>// newly updated x</span>
  gsl_vector *res_old    = gsl_vector_calloc(m);  <span style='color:#3f7f59; '>// previous residual</span>
  gsl_vector *res_new    = gsl_vector_calloc(m);  <span style='color:#3f7f59; '>// newly updated residual</span>
  gsl_vector *res        = gsl_vector_calloc(m);  <span style='color:#3f7f59; '>// current residual </span>
  gsl_vector *foo        = gsl_vector_calloc(m);  <span style='color:#3f7f59; '>// temporary variable</span>
  gsl_vector *lambda     = gsl_vector_calloc(m);  <span style='color:#3f7f59; '>// dual variable</span>
  gsl_vector *tmp        = gsl_vector_calloc(n);  <span style='color:#3f7f59; '>// temporary variable </span>
  gsl_vector *local_Ax   = gsl_vector_calloc(m);  <span style='color:#3f7f59; '>// the A_i x_i computed in each machine</span>
  gsl_vector *global_Ax  = gsl_vector_calloc(m);  <span style='color:#3f7f59; '>// the sum A_i x_i</span>
  gsl_vector *grad       = gsl_vector_calloc(n);  <span style='color:#3f7f59; '>// gradient </span>
  gsl_vector *z          = gsl_vector_calloc(m);  <span style='color:#3f7f59; '>// temporary variable </span>
  gsl_vector *x_diff     = gsl_vector_calloc(n);  <span style='color:#3f7f59; '>// the difference between x and xs</span>
  
  <span style='color:#7f0055; font-weight:bold; '>double</span> <span style='color:#7f0055; font-weight:bold; '>send</span>[3]; <span style='color:#3f7f59; '>// an array used to aggregate 3 scalars at once</span>
  <span style='color:#7f0055; font-weight:bold; '>double</span> <span style='color:#7f0055; font-weight:bold; '>recv</span>[3]; <span style='color:#3f7f59; '>// used to receive the results of these aggregations</span>
  
  gsl_blas_ddot(xs, xs, &amp;<span style='color:#7f0055; font-weight:bold; '>send</span>[1]); <span style='color:#3f7f59; '>// compute the 2-norm of xs</span>
  
  <span style='color:#3f7f59; '>/* Main Jacobi ADMM solver loop */</span>
  <span style='color:#7f0055; font-weight:bold; '>int</span> iter = 0;
  <span style='color:#7f0055; font-weight:bold; '>if</span> (rank == 0) 
  {
    <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>%3s</span><span style='color:#2a00ff; '> </span><span style='color:#2a00ff; '>%10s</span><span style='color:#2a00ff; '> </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>, <span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>#</span><span style='color:#2a00ff; '>"</span>, <span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>relative error</span><span style='color:#2a00ff; '>"</span>);
    <span style='color:#7f0055; font-weight:bold; '>sprintf</span>(s, <span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>results/test.m</span><span style='color:#2a00ff; '>"</span>);      <span style='color:#3f7f59; '>// read results into a test.m file</span>
    test = <span style='color:#7f0055; font-weight:bold; '>fopen</span>(s, <span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>w</span><span style='color:#2a00ff; '>"</span>);
    <span style='color:#7f0055; font-weight:bold; '>fprintf</span>(test,<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>res = [ </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
  }
  
  gsl_vector_memcpy(res_new, b);
  gsl_vector_scale(res_new, -1.0);
  
  totalStartTime = MPI_Wtime();      <span style='color:#3f7f59; '>// record the starting point of total time</span>
  <span style='color:#7f0055; font-weight:bold; '>while</span> (iter &lt; MAX_ITER) {

    startTime = MPI_Wtime();      <span style='color:#3f7f59; '>// record the starting point of a single iteration</span>
    <span style='color:#3f7f59; '>// update x, x_old</span>
    gsl_vector_memcpy(x_old, x);
    gsl_vector_memcpy(x, x_new);
    <span style='color:#3f7f59; '>// update res, res_old</span>
    gsl_vector_memcpy(res_old, res);
    gsl_vector_memcpy(res, res_new);
    
    <span style='color:#3f7f59; '>/* x-update:  */</span>
    <span style='color:#3f7f59; '>// calculate gradient</span>
    gsl_vector_memcpy(foo, res_new);
    gsl_vector_scale(foo, rho);	  
    gsl_vector_memcpy(z, foo);
    gsl_vector_sub(z, lambda);
    
    gsl_blas_dgemv(CblasTrans, 1, A, z, 0, grad);
    
    
    gsl_vector_memcpy(tmp, grad);
    gsl_vector_scale(tmp, -1.0/tau);
    gsl_vector_add(tmp, x_new);
    <span style='color:#3f7f59; '>// apply the shrinkage operator</span>
    soft_threshold(tmp, 1.0/tau);
    gsl_vector_memcpy(x_new, tmp);
    
    <span style='color:#3f7f59; '>/* lambda-update: */</span>
    <span style='color:#3f7f59; '>// calculate residual</span>
    gsl_blas_dgemv(CblasNoTrans, 1, A, x_new, 0, local_Ax);
    
    commStartTime = MPI_Wtime();
    MPI_Allreduce(local_Ax->data, global_Ax->data,  m, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);	  
    commEndTime = MPI_Wtime();
    
    gsl_vector_memcpy(res_new, global_Ax);
    gsl_vector_sub(res_new, b);
    
    gsl_vector_memcpy(foo, res_new);
    gsl_vector_scale(foo, gamma * rho);
    gsl_vector_sub(lambda, foo);
    
    <span style='color:#3f7f59; '>//calculate the difference of two iterations</span>
    gsl_vector_memcpy(x_diff, x);
    gsl_vector_sub(x_diff, x_new);
    
    <span style='color:#3f7f59; '>// check stopping criterion</span>
    
    gsl_blas_ddot(x_diff, x_diff, &amp;<span style='color:#7f0055; font-weight:bold; '>send</span>[0]);
    gsl_blas_ddot(x_new, x_new, &amp;<span style='color:#7f0055; font-weight:bold; '>send</span>[1]);
    <span style='color:#7f0055; font-weight:bold; '>send</span>[2] = gsl_blas_dasum(x);
    
    MPI_Allreduce(<span style='color:#7f0055; font-weight:bold; '>send</span>, <span style='color:#7f0055; font-weight:bold; '>recv</span>, 3, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
    
    
    <span style='color:#7f0055; font-weight:bold; '>if</span>(<span style='color:#7f0055; font-weight:bold; '>sqrt</span>(<span style='color:#7f0055; font-weight:bold; '>recv</span>[0])&lt; tol * <span style='color:#7f0055; font-weight:bold; '>sqrt</span>(<span style='color:#7f0055; font-weight:bold; '>recv</span>[1]))
      <span style='color:#7f0055; font-weight:bold; '>break</span>;

    <span style='color:#3f7f59; '>/* Dynamically update tau: proximal parameter*/</span>
    gsl_vector_memcpy(foo, res);
    gsl_vector_sub(foo, res_new);
    
    gsl_blas_ddot(res_new, foo, &amp;cross_term);
    cross_term = 2 * rho * cross_term;
    dx_nrm = tau * <span style='color:#7f0055; font-weight:bold; '>recv</span>[0];
    gsl_blas_ddot(res_new, res_new, &amp;dlam_nrm);
    dlam_nrm = (2 - gamma) * rho * dlam_nrm;
    lower_bnd = dx_nrm + dlam_nrm + cross_term;
    <span style='color:#7f0055; font-weight:bold; '>if</span>(lower_bnd &lt; 0)
    {
      tau = tau * 2;
      gsl_vector_memcpy(foo, res_new);
      gsl_vector_scale(foo, rho* gamma);
      gsl_vector_add(lambda, foo);
      
      gsl_vector_memcpy(res_new, res);
      gsl_vector_memcpy(res, res_old);
      
      gsl_vector_memcpy(x_new, x);
      gsl_vector_memcpy(x, x_old);
      
    }
    <span style='color:#7f0055; font-weight:bold; '>else</span> <span style='color:#7f0055; font-weight:bold; '>if</span>(iter%10 == 0)
      tau = tau * 0.5;
    
    <span style='color:#3f7f59; '>// compute the relative error of x</span>
    gsl_vector_memcpy(x_diff, x_new);
    gsl_vector_sub(x_diff, xs);
    gsl_blas_ddot(x_diff, x_diff, &amp;<span style='color:#7f0055; font-weight:bold; '>send</span>[0]);
    gsl_blas_ddot(xs, xs, &amp;<span style='color:#7f0055; font-weight:bold; '>send</span>[1]);
    MPI_Allreduce(<span style='color:#7f0055; font-weight:bold; '>send</span>, <span style='color:#7f0055; font-weight:bold; '>recv</span>, 3, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
    
    <span style='color:#7f0055; font-weight:bold; '>if</span> (rank == 0) 
    {
      endTime = MPI_Wtime();
      <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>%3d</span><span style='color:#2a00ff; '> </span><span style='color:#2a00ff; '>%e</span><span style='color:#2a00ff; '> </span><span style='color:#2a00ff; '>%10.4f</span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>, iter,
	     <span style='color:#7f0055; font-weight:bold; '>sqrt</span>(<span style='color:#7f0055; font-weight:bold; '>recv</span>[0])/<span style='color:#7f0055; font-weight:bold; '>sqrt</span>(<span style='color:#7f0055; font-weight:bold; '>recv</span>[1]), <span style='color:#7f0055; font-weight:bold; '>recv</span>[2]);
      <span style='color:#7f0055; font-weight:bold; '>fprintf</span>(test, <span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>%e</span><span style='color:#2a00ff; '> </span><span style='color:#2a00ff; '>%e</span><span style='color:#2a00ff; '> </span><span style='color:#2a00ff; '>%e</span><span style='color:#2a00ff; '> </span><span style='color:#2a00ff; '>%e</span><span style='color:#2a00ff; '>;</span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>, <span style='color:#7f0055; font-weight:bold; '>sqrt</span>(<span style='color:#7f0055; font-weight:bold; '>recv</span>[0])/<span style='color:#7f0055; font-weight:bold; '>sqrt</span>(<span style='color:#7f0055; font-weight:bold; '>recv</span>[1]), <span style='color:#7f0055; font-weight:bold; '>recv</span>[2],
	      endTime - startTime, commEndTime - commStartTime);
    }
    iter++;
    
  }
  
  <span style='color:#3f7f59; '>/* Have the master write out the results to disk */</span>
  <span style='color:#7f0055; font-weight:bold; '>if</span>(rank==0){
    totalEndTime =MPI_Wtime();
    <span style='color:#7f0055; font-weight:bold; '>fprintf</span>(test, <span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>]; </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
    <span style='color:#7f0055; font-weight:bold; '>fprintf</span>(test,<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>semilogy(1:length(res),res); </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
    <span style='color:#7f0055; font-weight:bold; '>fprintf</span>(test,<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>xlabel('# of iteration'); ylabel('||x - xs||/||xs||');</span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>);
    <span style='color:#7f0055; font-weight:bold; '>printf</span>(<span style='color:#2a00ff; '>"</span><span style='color:#2a00ff; '>Elapsed time is: </span><span style='color:#2a00ff; '>%lf</span><span style='color:#2a00ff; '> </span><span style='color:#2a00ff; '>\n</span><span style='color:#2a00ff; '>"</span>, totalEndTime - totalStartTime);
  }
 
  MPI_Finalize(); <span style='color:#3f7f59; '>/* Shut down the MPI execution environment */</span>
  
  <span style='color:#3f7f59; '>/* Clear memory */</span>
  gsl_matrix_free(A);
  gsl_vector_free(b);
  gsl_vector_free(x);
  gsl_vector_free(z);
  gsl_vector_free(x_new);
  gsl_vector_free(x_old);
  gsl_vector_free(foo);
  gsl_vector_free(tmp);
  gsl_vector_free(res_new);
  gsl_vector_free(res_old);
  gsl_vector_free(x_diff);
  gsl_vector_free(local_Ax);
  gsl_vector_free(global_Ax);
  gsl_vector_free(res);
  gsl_vector_free(grad);
  gsl_vector_free(lambda);

  <span style='color:#7f0055; font-weight:bold; '>return</span> EXIT_SUCCESS;
}

<span style='color:#7f0055; font-weight:bold; '>void</span> soft_threshold(gsl_vector *v, <span style='color:#7f0055; font-weight:bold; '>double</span> k) 
{
  <span style='color:#7f0055; font-weight:bold; '>double</span> vi;
  <span style='color:#7f0055; font-weight:bold; '>for</span> (<span style='color:#7f0055; font-weight:bold; '>int</span> i = 0; i &lt; v->size; i++) 
  {
    vi = gsl_vector_get(v, i);
    <span style='color:#7f0055; font-weight:bold; '>if</span> (vi > k)       { gsl_vector_set(v, i, vi - k); }
    <span style='color:#7f0055; font-weight:bold; '>else</span> <span style='color:#7f0055; font-weight:bold; '>if</span> (vi &lt; -k) { gsl_vector_set(v, i, vi + k); }
    <span style='color:#7f0055; font-weight:bold; '>else</span>              { gsl_vector_set(v, i, 0); }
  }
}
</pre>
